[yoloModel]
classnames=ARM,BIG_TIP,CHOPSTICK,SMALL_TIP
cfgpath=src/main/resources/detection/yolo-model/yolov3.cfg
weightspath=src/main/resources/detection/yolo-model/yolov3.weights

[objectDetection]
minConfidence=0.1
minTipConfidence=0.9
minChopstickConfidence=0.7
minArmConfidence=0.7
nmsThreshold=0.4
# implementation can be "opencvdnn" or "darknet"
implementation=opencvdnn
cacheFolderPath=output/cache

[tracking]
# In order to track a tip over several video frames, we compare each detected tip of one frame
# with all other tips of the previous frame. If the distance between two tip detections (one in the current
# frame, one in the previous frame) is small enough, then we consider these detections as part of the
# same tip. The following parameter defines the maximum distance (in pixels) between two tip detections
# in order to consider them as the same tip. Note that this distance is computed like this:
# dist_between(tip1.position, tip2.position) + abs(tip1.width - tip2.width) + abs(tip1.height - tip2.height)
maxTipMatchingDistanceInPixels=40
# The camera may move when capturing the scene. In order to compensate for that, we consider each
# video frames two by two, then we try to match tips between the two frames, and finally compute a
# "frame offset" by averaging the translations of the matched tips. The following parameter defines
# how many tips (that moved the less between the two frames) to consider for the calculation.
nbTipsToUseToDetectCameraMotion=5
# When tracking a tip, its position and size is calculated by averaging the positions and sizes
# of its detections over several video frames. The following parameter defines how many frames to
# consider for this computation.
nbDetectionsToComputeAverageTipPositionAndSize=9
# In order to track tips hidden by an arm, we need to first detect the area of the frame hidden by
# this arm. Unfortunately the rectangle we obtain when detecting the arm is too large, so it also
# includes areas that are not hidden. A solution is to calculate the distance between the supposed
# position of an undetected tip (located within a detected arm rectangle) with the surrounding
# objects: if there is a detected object nearby, it means the area is not covered by the arm; however,
# if there is no detected object near the undetected tip, it means that this area is
# indeed hidden by the arm. The following parameter defines the minimum matching distance between
# the missing tip and other surrounding objects in order to consider the tip as hidden by an arm.
minMatchingDistanceWithAnyObjectToConsiderTipNotHiddenByArm=20
# Because object detection is not perfect, it may happen that a visible tip is undetected for several
# frames. We compensate for that by remembering the position of a tip when it is undetected. The
# following parameter defines the maximum number of frames to wait until an undetected tip is
# considered as lost.
maxFramesAfterWhichATipIsConsideredLost=7
# Sometime, a tip is detected twice in the same video frame. We compensate by deleting the
# superfluous tip detection when it is too close to an existing tip. The following parameter defines
# the minimum distance between two tips in order to be considered as the same.
minDistanceToConsiderNewTipAsTheSameAsAnExistingOne=15
# Minimum distance between two tips that may belong to the same chopstick.
minChopstickLengthInPixels=350
# Maximum distance between two tips that may belong to the same chopstick.
maxChopstickLengthInPixels=550
# In order to verify that two tips belong to a detected chopstick, we calculate the
# intersection over Union (IoU) with the bounding box that surrounds the tips and a detected chopstick.
# The following parameter defines the minimum IoU in order to consider that two tips belong to a chopstick.
minIOUToConsiderTwoTipsAsAChopstick=0.2
# Because object detection is not perfect, it may happen that a visible chopstick is undetected for several
# frames. We compensate for that by remembering the position of a chopstick when it is undetected. The
# following parameter defines the maximum number of frames to wait until an undetected chopstick is
# considered as lost.
maxFramesAfterWhichAChopstickIsConsideredLost=70

[rendering]
outputpath=output/result
# painterImplementations can be "detectedobjects", "trackedobjects" or "detectedobjects,trackedobjects"
painterImplementations=detectedobjects,trackedobjects
detectedobjectsPainter_showTips=false
detectedobjectsPainter_showChopsticks=false
detectedobjectsPainter_showArms=false
trackedobjectsPainter_showTips=true
trackedobjectsPainter_showAcceptedChopsticks=true
trackedobjectsPainter_showRejectedChopsticks=false
# writerImplementation can be "mjpeg" (.avi video file) or "multijpeg" (multiple .jpg images in a folder)
writerImplementation=mjpeg
# The margins (left, right, top, bottom) are black bands around the frame in order to compensate for
# camera motion.
videoFrameMarginsInPixels=110